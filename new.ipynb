{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f279e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2651dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic.datasets.nmnist import NMNIST\n",
    "from tonic.transforms import ToFrame\n",
    "\n",
    "root_dir = \"./NMNIST\"\n",
    "NMNIST(save_to=root_dir, train=True)\n",
    "NMNIST(save_to=root_dir, train=False)\n",
    "\n",
    "to_raster = ToFrame(sensor_size=(34, 34), n_time_bins=100)\n",
    "dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49842437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(2, 8, 3, padding=1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2),\n",
    "    nn.Conv2d(8, 16, 3, padding=1, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2),\n",
    "    nn.Conv2d(16, 16, 3, padding=1, stride=2, bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256, 10, bias=False),\n",
    "    nn.ReLU()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "188a7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "\n",
    "snn_convert = from_model(model=cnn, input_shape=(2, 34, 34), batch_size=4).spiking_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18aeb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network is valid\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'speck2fdevkit:0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m cpu_snn \u001b[38;5;241m=\u001b[39m snn_convert\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m dynapcnn \u001b[38;5;241m=\u001b[39m DynapcnnNetwork(snn\u001b[38;5;241m=\u001b[39mcpu_snn, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m34\u001b[39m), discretize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dvs_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdynapcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeck2fdevkit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchip_layers_ordering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/py310/lib/python3.10/site-packages/sinabs/backend/dynapcnn/dynapcnn_network.py:155\u001b[0m, in \u001b[0;36mDynapcnnNetwork.to\u001b[0;34m(self, device, chip_layers_ordering, monitor_layers, config_modifier, slow_clk_frequency)\u001b[0m\n\u001b[1;32m    147\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_config(\n\u001b[1;32m    148\u001b[0m     chip_layers_ordering\u001b[38;5;241m=\u001b[39mchip_layers_ordering,\n\u001b[1;32m    149\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m    150\u001b[0m     monitor_layers\u001b[38;5;241m=\u001b[39mmonitor_layers,\n\u001b[1;32m    151\u001b[0m     config_modifier\u001b[38;5;241m=\u001b[39mconfig_modifier,\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Apply configuration to device\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamna_device \u001b[38;5;241m=\u001b[39m \u001b[43mopen_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamna_device\u001b[38;5;241m.\u001b[39mget_model()\u001b[38;5;241m.\u001b[39mapply_configuration(config)\n\u001b[1;32m    157\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/py310/lib/python3.10/site-packages/sinabs/backend/dynapcnn/io.py:255\u001b[0m, in \u001b[0;36mopen_device\u001b[0;34m(device_id)\u001b[0m\n\u001b[1;32m    253\u001b[0m device_id \u001b[38;5;241m=\u001b[39m standardize_device_id(device_id\u001b[38;5;241m=\u001b[39mdevice_id)\n\u001b[1;32m    254\u001b[0m device_map \u001b[38;5;241m=\u001b[39m get_device_map()\n\u001b[0;32m--> 255\u001b[0m device_info \u001b[38;5;241m=\u001b[39m \u001b[43mdevice_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    256\u001b[0m device_handle \u001b[38;5;241m=\u001b[39m samna\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mopen_device(device_info)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'speck2fdevkit:0'"
     ]
    }
   ],
   "source": [
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "\n",
    "cpu_snn = snn_convert.to(\"cpu\")\n",
    "dynapcnn = DynapcnnNetwork(snn=cpu_snn, input_shape=(2, 34, 34), discretize=True, dvs_input=False)\n",
    "dynapcnn.to(device=\"speck2fdevkit\", chip_layers_ordering=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e666c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinabs.backend.dynapcnn.dynapcnn_visualizer import DynapcnnVisualizer\n",
    "\n",
    "visualizer = DynapcnnVisualizer(window_scale=(4, 8), dvs_shape=(34, 34), spike_collection_interval=50)\n",
    "visualizer.connect(dynapcnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5393ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvs_event = samna.speck2f.event.DvsEvent()\n",
    "# 设置 dvs_event 的属性：x, y, t, p\n",
    "# 然后发送到 devkit 推理\n",
    "output = dynapcnn([dvs_event])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d691a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import samna\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "\n",
    "# 打开设备\n",
    "devices = samna.device.get_unopened_devices()\n",
    "if len(devices) == 0:\n",
    "    raise Exception(\"No devices found\")\n",
    "\n",
    "# 打开第一个设备\n",
    "my_board = samna.device.open_device(devices[0])\n",
    "\n",
    "# 获取设备的 serial_number\n",
    "device_id = my_board.get_serial_number()  # 获取设备的 serial_number 作为设备 ID\n",
    "\n",
    "# 你的 SNN 模型，例如通过 CNN -> SNN 转换得到\n",
    "snn_model = from_model(\n",
    "    model=cnn,  # 你的 CNN 模型\n",
    "    input_shape=(2, 34, 34),\n",
    "    batch_size=4\n",
    ").spiking_model\n",
    "\n",
    "# 包装为 DynapcnnNetwork\n",
    "dynapcnn = DynapcnnNetwork(\n",
    "    snn=snn_model.to(\"cpu\"),\n",
    "    input_shape=(2, 34, 34),\n",
    "    discretize=True,\n",
    "    dvs_input=False\n",
    ")\n",
    "\n",
    "# ✅ 使用 serial_number 作为设备标识符\n",
    "dynapcnn.to(device=device_id, chip_layers_ordering=\"auto\")\n",
    "\n",
    "print(f\"✅ 模型成功部署到 SPECK！部署到核心顺序为: {dynapcnn.chip_layers_ordering}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4325ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tonic.datasets.nmnist import NMNIST\n",
    "from tonic.transforms import ToFrame\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import samna\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "from sinabs.backend.dynapcnn.dynapcnn_visualizer import DynapcnnVisualizer\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "# 数据下载并准备\n",
    "root_dir = \"./NMNIST\"\n",
    "_ = NMNIST(save_to=root_dir, train=True)\n",
    "_ = NMNIST(save_to=root_dir, train=False)\n",
    "\n",
    "# 数据预处理\n",
    "to_frame = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=1)\n",
    "cnn_train_dataset = NMNIST(save_to=root_dir, train=True, transform=to_frame)\n",
    "cnn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_frame)\n",
    "\n",
    "# 定义CNN模型\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=(1, 1), stride=(2, 2),  bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 4 * 4, 10, bias=False),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "# 初始化CNN权重\n",
    "for layer in cnn.modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(layer.weight.data)\n",
    "\n",
    "# 训练CNN\n",
    "epochs = 1\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "device = \"cpu\"\n",
    "cnn = cnn.to(device=device)\n",
    "cnn_train_dataloader = DataLoader(cnn_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "cnn_test_dataloader = DataLoader(cnn_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optimizer = SGD(params=cnn.parameters(), lr=lr)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "for e in range(epochs):\n",
    "    train_p_bar = tqdm(cnn_train_dataloader)\n",
    "    for data, label in train_p_bar:\n",
    "        data = data.squeeze(dim=1).to(device=device, dtype=torch.float)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_p_bar.set_description(f\"Epoch {e} - Training Loss: {round(loss.item(), 4)}\")\n",
    "\n",
    "    # 验证CNN\n",
    "    correct_predictions = []\n",
    "    with torch.no_grad():\n",
    "        test_p_bar = tqdm(cnn_test_dataloader)\n",
    "        for data, label in test_p_bar:\n",
    "            data = data.squeeze(dim=1).to(device=device, dtype=torch.float)\n",
    "            label = label.to(device=device, dtype=torch.long)\n",
    "            output = cnn(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "        correct_predictions = torch.cat(correct_predictions)\n",
    "        print(f\"Epoch {e} - accuracy: {correct_predictions.sum().item() / len(correct_predictions) * 100}%\")\n",
    "\n",
    "# CNN转SNN\n",
    "snn_convert = from_model(model=cnn, input_shape=(2, 34, 34), batch_size=batch_size).spiking_model\n",
    "\n",
    "# 定义SNN测试数据集\n",
    "n_time_steps = 100\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 测试SNN\n",
    "snn_convert = snn_convert.to(device)\n",
    "correct_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_p_bar = tqdm(snn_test_dataloader)\n",
    "    for data, label in test_p_bar:\n",
    "        data = data.reshape(-1, 2, 34, 34).to(device=device, dtype=torch.float)\n",
    "        label = label.to(device=device, dtype=torch.long)\n",
    "        output = snn_convert(data)\n",
    "        output = output.reshape(batch_size, n_time_steps, -1)\n",
    "        output = output.sum(dim=1)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    print(f\"accuracy of converted SNN: {correct_predictions.sum().item() / len(correct_predictions) * 100}%\")\n",
    "\n",
    "# 将SNN部署到Devkit\n",
    "cpu_snn = snn_convert.to(device=\"cpu\")\n",
    "dynapcnn = DynapcnnNetwork(snn=cpu_snn, input_shape=(2, 34, 34), discretize=True, dvs_input=False)\n",
    "devkit_name = \"speck2fmodule\"\n",
    "dynapcnn.to(device=devkit_name, chip_layers_ordering=\"auto\")\n",
    "print(f\"The SNN is deployed on the core: {dynapcnn.chip_layers_ordering}\")\n",
    "\n",
    "# 生成事件流并进行推理\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False)\n",
    "subset_indices = list(range(0, len(snn_test_dataset), 100))\n",
    "snn_test_dataset = Subset(snn_test_dataset, subset_indices)\n",
    "\n",
    "inferece_p_bar = tqdm(snn_test_dataset)\n",
    "test_samples = 0\n",
    "correct_samples = 0\n",
    "for events, label in inferece_p_bar:\n",
    "    samna_event_stream = []\n",
    "    for ev in events:\n",
    "        spk = samna.speck2f.event.Spike()\n",
    "        spk.x = ev['x']\n",
    "        spk.y = ev['y']\n",
    "        spk.timestamp = ev['t'] - events['t'][0]\n",
    "        spk.feature = ev['p']\n",
    "        spk.layer = 0\n",
    "        samna_event_stream.append(spk)\n",
    "\n",
    "    output_events = dynapcnn(samna_event_stream)\n",
    "    neuron_index = [each.feature for each in output_events]\n",
    "    if len(neuron_index) != 0:\n",
    "        frequent_counter = Counter(neuron_index)\n",
    "        prediction = frequent_counter.most_common(1)[0][0]\n",
    "    else:\n",
    "        prediction = -1\n",
    "    inferece_p_bar.set_description(f\"label: {label}, prediction: {prediction}, output spikes num: {len(output_events)}\")\n",
    "\n",
    "    if prediction == label:\n",
    "        correct_samples += 1\n",
    "    test_samples += 1\n",
    "print(f\"On chip inference accuracy: {correct_samples / test_samples}\")\n",
    "\n",
    "# 可视化SNN部署\n",
    "visualizer = DynapcnnVisualizer(\n",
    "    window_scale=(4, 8),\n",
    "    dvs_shape=(34, 34),\n",
    "    spike_collection_interval=50,\n",
    ")\n",
    "\n",
    "visualizer.connect(dynapcnn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
