{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T18:13:21.131256Z",
     "start_time": "2025-04-18T18:13:17.960705Z"
    }
   },
   "source": [
    "# 导入必需的库\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.optim import SGD,Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "import samna\n",
    "from tonic.datasets import NMNIST\n",
    "from tonic.transforms import ToFrame\n",
    "from sinabs.from_torch import from_model\n",
    "from sinabs.backend.dynapcnn import DynapcnnNetwork\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:40:36.931404Z",
     "start_time": "2025-04-18T17:40:33.194075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 数据准备\n",
    "root_dir = \"./NMNIST\"\n",
    "try:\n",
    "    from tonic.datasets.nmnist import NMNIST\n",
    "except ImportError:\n",
    "    !pip install tonic\n",
    "    from tonic.datasets.nmnist import NMNIST\n",
    "\n",
    "# 下载 N-MNIST 数据集\n",
    "_ = NMNIST(save_to=root_dir, train=True)\n",
    "_ = NMNIST(save_to=root_dir, train=False)\n",
    "\n",
    "# 使用 Tonic 转换事件数据为帧\n",
    "to_frame = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=1)\n",
    "cnn_train_dataset = NMNIST(save_to=root_dir, train=True, transform=to_frame)\n",
    "cnn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_frame)\n",
    "\n",
    "# 打印一下数据的形状\n",
    "sample_data, label = cnn_train_dataset[0]\n",
    "print(f\"The transformed array is in shape [Time-Step, Channel, Height, Width] --> {sample_data.shape}\")"
   ],
   "id": "55335e3810f92b50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transformed array is in shape [Time-Step, Channel, Height, Width] --> (1, 2, 34, 34)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:46:56.585022Z",
     "start_time": "2025-04-18T17:46:56.571300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义 CNN 模型\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=2, out_channels=8, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(2, 2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=(1, 1), stride=(2, 2), bias=False),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 4 * 4, 10, bias=False),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "# 初始化模型权重\n",
    "for layer in cnn.modules():\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.xavier_normal_(layer.weight.data)\n",
    "\n",
    "# 训练和验证 CNN\n",
    "epochs = 1\n",
    "lr = 1e-3\n",
    "batch_size = 64\n",
    "num_workers = 16\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "shuffle = True\n",
    "\n",
    "cnn = cnn.to(device=device)\n",
    "\n",
    "cnn_train_dataloader = DataLoader(cnn_train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
    "cnn_test_dataloader = DataLoader(cnn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
    "\n",
    "optimizer = Adam(params=cnn.parameters(), lr=lr)\n",
    "criterion = CrossEntropyLoss()"
   ],
   "id": "2afaa17f45f66514",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:46:58.040698Z",
     "start_time": "2025-04-18T17:46:58.035967Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "c3a056a4d000083e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:49:00.112904Z",
     "start_time": "2025-04-18T17:46:59.454203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(epochs):\n",
    "    # Train the model\n",
    "    train_p_bar = tqdm(cnn_train_dataloader)\n",
    "    for data, label in train_p_bar:\n",
    "        data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_p_bar.set_description(f\"Epoch {e} - Training Loss: {round(loss.item(), 4)}\")\n",
    "\n",
    "    # Validate the model\n",
    "    correct_predictions = []\n",
    "    with torch.no_grad():\n",
    "        test_p_bar = tqdm(cnn_test_dataloader)\n",
    "        for data, label in test_p_bar:\n",
    "            data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "            label = label.to(dtype=torch.long, device=device)\n",
    "            output = cnn(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "            test_p_bar.set_description(f\"Epoch {e} - Testing Model...\")\n",
    "\n",
    "        correct_predictions = torch.cat(correct_predictions)\n",
    "        print(f\"Epoch {e} - accuracy: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")"
   ],
   "id": "b4293a9b138ffc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training Loss: 0.4992: 100%|██████████| 937/937 [01:34<00:00,  9.87it/s]\n",
      "Epoch 0 - Testing Model...: 100%|██████████| 156/156 [00:25<00:00,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - accuracy: 74.70953525641025%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:49:39.312865Z",
     "start_time": "2025-04-18T17:49:38.606091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "reset18=models.resnet18(pretrained=True)\n",
    "reset18=reset18.to(device)"
   ],
   "id": "b729867b272fb59e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:54:10.686788Z",
     "start_time": "2025-04-18T17:54:10.680401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1=nn.Sequential(   nn.Conv2d(in_channels=2, out_channels=3, kernel_size=(3, 3), padding=(1, 1), bias=False),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.AvgPool2d(2, 2),)\n",
    "        self.l2=models.resnet18(pretrained=True)\n",
    "        self.l3=nn.Linear(1000,10);\n",
    "    def forward(self,x):\n",
    "        x=self.l1(x)\n",
    "        x=self.l2(x)\n",
    "        x=self.l3(x)\n",
    "        return x"
   ],
   "id": "7a7a9586389e7a3c",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:54:12.159828Z",
     "start_time": "2025-04-18T17:54:11.918763Z"
    }
   },
   "cell_type": "code",
   "source": "resnet18=resnet()",
   "id": "da0a6ec0b8c68e3",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:54:12.850208Z",
     "start_time": "2025-04-18T17:54:12.779522Z"
    }
   },
   "cell_type": "code",
   "source": "resnet18=resnet18.to(device)",
   "id": "e12ea0e4ab88c33f",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:54:13.672578Z",
     "start_time": "2025-04-18T17:54:13.666656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练和验证 CNN\n",
    "epochs = 1\n",
    "lr = 1e-3\n",
    "batch_size = 32\n",
    "num_workers = 22\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "shuffle = True\n",
    "\n",
    "#cnn = cnn.to(device=device)\n",
    "\n",
    "cnn_train_dataloader = DataLoader(cnn_train_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
    "cnn_test_dataloader = DataLoader(cnn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=shuffle)\n",
    "\n",
    "optimizer = Adam(params=resnet18.parameters(), lr=lr)\n",
    "criterion = CrossEntropyLoss()"
   ],
   "id": "8c84f797df3c5bcf",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T17:55:40.948799Z",
     "start_time": "2025-04-18T17:54:15.730467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for e in range(epochs):\n",
    "    # Train the model\n",
    "    train_p_bar = tqdm(cnn_train_dataloader)\n",
    "    for data, label in train_p_bar:\n",
    "        data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        output = resnet18(data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_p_bar.set_description(f\"Epoch {e} - Training Loss: {round(loss.item(), 4)}\")\n",
    "\n",
    "    # Validate the model\n",
    "    correct_predictions = []\n",
    "    with torch.no_grad():\n",
    "        test_p_bar = tqdm(cnn_test_dataloader)\n",
    "        for data, label in test_p_bar:\n",
    "            data = data.squeeze(dim=1).to(dtype=torch.float, device=device)\n",
    "            label = label.to(dtype=torch.long, device=device)\n",
    "            output = resnet18(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "            test_p_bar.set_description(f\"Epoch {e} - Testing Model...\")\n",
    "\n",
    "        correct_predictions = torch.cat(correct_predictions)\n",
    "        print(f\"Epoch {e} - accuracy: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")"
   ],
   "id": "346986fed87dd504",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training Loss: 0.8313: 100%|██████████| 1875/1875 [01:10<00:00, 26.65it/s]\n",
      "Epoch 0 - Testing Model...: 100%|██████████| 312/312 [00:14<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - accuracy: 89.1826923076923%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:04:47.613964Z",
     "start_time": "2025-04-18T18:04:05.183358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CNN 转 SNN\n",
    "snn_convert = from_model(model=cnn, input_shape=(2, 34, 34), batch_size=batch_size).spiking_model\n",
    "\n",
    "# 转换后的 SNN 测试\n",
    "n_time_steps = 100\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "snn_convert = snn_convert.to(device)\n",
    "\n",
    "correct_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_p_bar = tqdm(snn_test_dataloader)\n",
    "    for data, label in test_p_bar:\n",
    "        data = data.reshape(-1, 2, 34, 34).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        output = snn_convert(data)\n",
    "        output = output.reshape(batch_size, n_time_steps, -1)\n",
    "        output = output.sum(dim=1)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "        test_p_bar.set_description(f\"Testing SNN Model...\")\n",
    "\n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    print(f\"accuracy of converted SNN: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")\n"
   ],
   "id": "f7fa6fb053fb7627",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SNN Model...: 100%|██████████| 312/312 [00:41<00:00,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of converted SNN: 73.23717948717949%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#It's similar to the cnn",
   "id": "8ee5248bdb211d49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:03:00.192818Z",
     "start_time": "2025-04-18T17:58:11.455829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# res18 转 SNN\n",
    "snn_convert = from_model(model=resnet18, input_shape=(2, 34, 34), batch_size=batch_size).spiking_model\n",
    "\n",
    "# 转换后的 SNN 测试\n",
    "n_time_steps = 200\n",
    "to_raster = ToFrame(sensor_size=NMNIST.sensor_size, n_time_bins=n_time_steps)\n",
    "snn_test_dataset = NMNIST(save_to=root_dir, train=False, transform=to_raster)\n",
    "snn_test_dataloader = DataLoader(snn_test_dataset, batch_size=batch_size, num_workers=num_workers, drop_last=True, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "snn_convert = snn_convert.to(device)\n",
    "\n",
    "correct_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_p_bar = tqdm(snn_test_dataloader)\n",
    "    for data, label in test_p_bar:\n",
    "        data = data.reshape(-1, 2, 34, 34).to(dtype=torch.float, device=device)\n",
    "        label = label.to(dtype=torch.long, device=device)\n",
    "        output = snn_convert(data)\n",
    "        output = output.reshape(batch_size, n_time_steps, -1)\n",
    "        output = output.sum(dim=1)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct_predictions.append(pred.eq(label.view_as(pred)))\n",
    "        test_p_bar.set_description(f\"Testing SNN Model...\")\n",
    "\n",
    "    correct_predictions = torch.cat(correct_predictions)\n",
    "    print(f\"accuracy of converted SNN: {correct_predictions.sum().item()/(len(correct_predictions))*100}%\")\n"
   ],
   "id": "ba14c66071e2a72e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing SNN Model...: 100%|██████████| 312/312 [04:48<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of converted SNN: 8.713942307692307%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:11:59.586061Z",
     "start_time": "2025-04-18T18:11:59.147425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 部署 SNN 到 Devkit\n",
    "cpu_snn = snn_convert.to(device=\"cpu\")\n",
    "devices = samna.device.get_unopened_devices()\n",
    "if len(devices) == 0:\n",
    "    raise Exception(\"No devices found\")\n",
    "my_board = samna.device.open_device(devices[0])\n",
    "\n",
    "# 使用设备信息部署到 DevKit\n",
    "devkit_name = my_board.devkit_name\n",
    "dynapcnn = DynapcnnNetwork(snn=cpu_snn, input_shape=(2, 34, 34), discretize=True, dvs_input=False)\n",
    "dynapcnn.to(device=devkit_name, chip_layers_ordering=\"auto\")\n",
    "\n",
    "print(f\"The SNN is deployed on the core: {dynapcnn.chip_layers_ordering}\")"
   ],
   "id": "366883d093d433e",
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No devices found",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mException\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[34]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m devices = samna.device.get_unopened_devices()\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(devices) == \u001B[32m0\u001B[39m:\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo devices found\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m my_board = samna.device.open_device(devices[\u001B[32m0\u001B[39m])\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# 使用设备信息部署到 DevKit\u001B[39;00m\n",
      "\u001B[31mException\u001B[39m: No devices found"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T18:13:34.320991Z",
     "start_time": "2025-04-18T18:13:33.900387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "devices = samna.device.get_unopened_devices()\n",
    "devices"
   ],
   "id": "62bd9c28b3a8781b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
